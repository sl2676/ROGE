/**
 * DO NOT EDIT THIS FILE!
 * File automatically generated by
 *   /home/sean/gem5-rtl/src/mem/slicc/symbols/StateMachine.py:1225
 */

// Created by slicc definition of Module "Memory controller interface"

#include <sys/types.h>
#include <unistd.h>

#include <cassert>
#include <sstream>
#include <string>
#include <typeinfo>

#include "mem/ruby/common/BoolVec.hh"

#include "base/compiler.hh"
#include "base/cprintf.hh"

#include "debug/RubySlicc.hh"
#include "debug/RubyGenerated.hh"
#include "mem/ruby/network/Network.hh"
#include "mem/ruby/protocol/Memory_Controller.hh"
#include "mem/ruby/protocol/Memory_Event.hh"
#include "mem/ruby/protocol/Memory_State.hh"
#include "mem/ruby/protocol/Types.hh"
#include "mem/ruby/system/RubySystem.hh"

#include "mem/ruby/slicc_interface/RubySlicc_includes.hh"
#include "mem/ruby/protocol/TBETable.hh"
#include "mem/ruby/protocol/TBEStorage.hh"
#include "mem/ruby/protocol/TriggerQueue.hh"
namespace gem5
{

namespace ruby
{

int Memory_Controller::m_num_controllers = 0;
std::vector<statistics::Vector *>  Memory_Controller::eventVec;
std::vector<std::vector<statistics::Vector *> >  Memory_Controller::transVec;

// for adding information to the protocol debug trace
std::stringstream Memory_transitionComment;

#ifndef NDEBUG
#define APPEND_TRANSITION_COMMENT(str) (Memory_transitionComment << str)
#else
#define APPEND_TRANSITION_COMMENT(str) do {} while (0)
#endif

/** \brief constructor */
Memory_Controller::Memory_Controller(const Params &p)
    : AbstractController(p)
{
    m_machineID.type = MachineType_Memory;
    m_machineID.num = m_version;
    m_num_controllers++;
    p.ruby_system->registerAbstractController(this);

    m_in_ports = 7;
    m_response_latency = p.response_latency;
    m_data_latency = p.data_latency;
    m_to_memory_controller_latency = p.to_memory_controller_latency;
    m_data_channel_size = p.data_channel_size;
    m_reqOut_ptr = p.reqOut;
    m_snpOut_ptr = p.snpOut;
    m_rspOut_ptr = p.rspOut;
    m_datOut_ptr = p.datOut;
    m_reqIn_ptr = p.reqIn;
    m_snpIn_ptr = p.snpIn;
    m_rspIn_ptr = p.rspIn;
    m_datIn_ptr = p.datIn;
    m_reqRdy_ptr = p.reqRdy;
    m_requestToMemory_ptr = p.requestToMemory;
    m_responseFromMemory_ptr = p.responseFromMemory;
    m_triggerQueue_ptr = p.triggerQueue;

    for (int state = 0; state < Memory_State_NUM; state++) {
        for (int event = 0; event < Memory_Event_NUM; event++) {
            m_possible[state][event] = false;
            m_counters[state][event] = 0;
        }
    }
    for (int event = 0; event < Memory_Event_NUM; event++) {
        m_event_counters[event] = 0;
    }
}

void
Memory_Controller::initNetQueues()
{
    MachineType machine_type = string_to_MachineType("Memory");
    GEM5_VAR_USED int base = MachineType_base_number(machine_type);

    assert(m_reqOut_ptr != NULL);
    m_net_ptr->setToNetQueue(m_version + base, m_reqOut_ptr->getOrdered(), 0,
                                     "none", m_reqOut_ptr);
    assert(m_snpOut_ptr != NULL);
    m_net_ptr->setToNetQueue(m_version + base, m_snpOut_ptr->getOrdered(), 1,
                                     "none", m_snpOut_ptr);
    assert(m_rspOut_ptr != NULL);
    m_net_ptr->setToNetQueue(m_version + base, m_rspOut_ptr->getOrdered(), 2,
                                     "none", m_rspOut_ptr);
    assert(m_datOut_ptr != NULL);
    m_net_ptr->setToNetQueue(m_version + base, m_datOut_ptr->getOrdered(), 3,
                                     "response", m_datOut_ptr);
    assert(m_reqIn_ptr != NULL);
    m_net_ptr->setFromNetQueue(m_version + base, m_reqIn_ptr->getOrdered(), 0,
                                     "none", m_reqIn_ptr);
    assert(m_snpIn_ptr != NULL);
    m_net_ptr->setFromNetQueue(m_version + base, m_snpIn_ptr->getOrdered(), 1,
                                     "none", m_snpIn_ptr);
    assert(m_rspIn_ptr != NULL);
    m_net_ptr->setFromNetQueue(m_version + base, m_rspIn_ptr->getOrdered(), 2,
                                     "none", m_rspIn_ptr);
    assert(m_datIn_ptr != NULL);
    m_net_ptr->setFromNetQueue(m_version + base, m_datIn_ptr->getOrdered(), 3,
                                     "response", m_datIn_ptr);
}

void
Memory_Controller::init()
{
    // initialize objects
    m_blockSize_ptr = new int;
    (*m_blockSize_ptr) = RubySystem::getBlockSizeBytes();
    m_TBEs_ptr  = new TBETable<Memory_TBE>(m_number_of_TBEs);
    assert(m_TBEs_ptr != NULL);
    m_storTBEs_ptr  = new TBEStorage(this, m_number_of_TBEs);
    assert(m_storTBEs_ptr != NULL);
    m_pendingWrites_ptr = new int;
    (*m_pendingWrites_ptr) = 0;
    m_retryQueue_ptr  = new TriggerQueue<Memory_RetryQueueEntry>();
    assert(m_retryQueue_ptr != NULL);


    (*m_rspIn_ptr).setConsumer(this);
    (*m_datIn_ptr).setConsumer(this);
    (*m_responseFromMemory_ptr).setConsumer(this);
    (*m_triggerQueue_ptr).setConsumer(this);
    (*m_snpIn_ptr).setConsumer(this);
    (*m_reqRdy_ptr).setConsumer(this);
    (*m_reqIn_ptr).setConsumer(this);

    possibleTransition(Memory_State_READY, Memory_Event_ReadNoSnp);
    possibleTransition(Memory_State_READY, Memory_Event_ReadNoSnpSep);
    possibleTransition(Memory_State_READING_MEM, Memory_Event_MemoryData);
    possibleTransition(Memory_State_SENDING_NET_DATA, Memory_Event_Trigger_Send);
    possibleTransition(Memory_State_READY, Memory_Event_WriteNoSnpPtl);
    possibleTransition(Memory_State_READY, Memory_Event_WriteNoSnp);
    possibleTransition(Memory_State_WAITING_NET_DATA, Memory_Event_WriteData);
    possibleTransition(Memory_State_WAITING_NET_DATA, Memory_Event_Trigger_ReceiveDone);
    possibleTransition(Memory_State_SENDING_NET_DATA, Memory_Event_Trigger_SendDone);
    possibleTransition(Memory_State_READING_MEM, Memory_Event_MemoryAck);
    possibleTransition(Memory_State_WAITING_NET_DATA, Memory_Event_MemoryAck);
    possibleTransition(Memory_State_SENDING_NET_DATA, Memory_Event_MemoryAck);
    possibleTransition(Memory_State_READY, Memory_Event_MemoryAck);
    possibleTransition(Memory_State_READING_MEM, Memory_Event_ReadNoSnp);
    possibleTransition(Memory_State_READING_MEM, Memory_Event_ReadNoSnpSep);
    possibleTransition(Memory_State_READING_MEM, Memory_Event_WriteNoSnpPtl);
    possibleTransition(Memory_State_WAITING_NET_DATA, Memory_Event_ReadNoSnp);
    possibleTransition(Memory_State_WAITING_NET_DATA, Memory_Event_ReadNoSnpSep);
    possibleTransition(Memory_State_WAITING_NET_DATA, Memory_Event_WriteNoSnpPtl);
    possibleTransition(Memory_State_SENDING_NET_DATA, Memory_Event_ReadNoSnp);
    possibleTransition(Memory_State_SENDING_NET_DATA, Memory_Event_ReadNoSnpSep);
    possibleTransition(Memory_State_SENDING_NET_DATA, Memory_Event_WriteNoSnpPtl);
    possibleTransition(Memory_State_READING_MEM, Memory_Event_Trigger_SendRetry);
    possibleTransition(Memory_State_WAITING_NET_DATA, Memory_Event_Trigger_SendRetry);
    possibleTransition(Memory_State_SENDING_NET_DATA, Memory_Event_Trigger_SendRetry);
    possibleTransition(Memory_State_READY, Memory_Event_Trigger_SendRetry);
    possibleTransition(Memory_State_READING_MEM, Memory_Event_Trigger_SendPCrdGrant);
    possibleTransition(Memory_State_WAITING_NET_DATA, Memory_Event_Trigger_SendPCrdGrant);
    possibleTransition(Memory_State_SENDING_NET_DATA, Memory_Event_Trigger_SendPCrdGrant);
    possibleTransition(Memory_State_READY, Memory_Event_Trigger_SendPCrdGrant);
    possibleTransition(Memory_State_READING_MEM, Memory_Event_CheckAllocTBE);
    possibleTransition(Memory_State_WAITING_NET_DATA, Memory_Event_CheckAllocTBE);
    possibleTransition(Memory_State_SENDING_NET_DATA, Memory_Event_CheckAllocTBE);
    possibleTransition(Memory_State_READY, Memory_Event_CheckAllocTBE);
    possibleTransition(Memory_State_READING_MEM, Memory_Event_CheckAllocTBE_WithCredit);
    possibleTransition(Memory_State_WAITING_NET_DATA, Memory_Event_CheckAllocTBE_WithCredit);
    possibleTransition(Memory_State_SENDING_NET_DATA, Memory_Event_CheckAllocTBE_WithCredit);
    possibleTransition(Memory_State_READY, Memory_Event_CheckAllocTBE_WithCredit);
    AbstractController::init();
    resetStats();
}

Sequencer*
Memory_Controller::getCPUSequencer() const
{
    return NULL;
}

DMASequencer*
Memory_Controller::getDMASequencer() const
{
    return NULL;
}

GPUCoalescer*
Memory_Controller::getGPUCoalescer() const
{
    return NULL;
}

void
Memory_Controller::regStats()
{
    AbstractController::regStats();

    // For each type of controllers, one controller of that type is picked
    // to aggregate stats of all controllers of that type. 
    if (m_version == 0) {

        Profiler *profiler = params().ruby_system->getProfiler();
        statistics::Group *profilerStatsPtr = &profiler->rubyProfilerStats;

        for (Memory_Event event = Memory_Event_FIRST;
             event < Memory_Event_NUM; ++event) {
            std::string stat_name =
                "Memory_Controller." + Memory_Event_to_string(event);
            statistics::Vector *t =
                new statistics::Vector(profilerStatsPtr, stat_name.c_str());
            t->init(m_num_controllers);
            t->flags(statistics::pdf | statistics::total |
                statistics::oneline | statistics::nozero);

            eventVec.push_back(t);
        }

        for (Memory_State state = Memory_State_FIRST;
             state < Memory_State_NUM; ++state) {

            transVec.push_back(std::vector<statistics::Vector *>());

            for (Memory_Event event = Memory_Event_FIRST;
                 event < Memory_Event_NUM; ++event) {
                std::string stat_name = "Memory_Controller." +
                    Memory_State_to_string(state) +
                    "." + Memory_Event_to_string(event);
                statistics::Vector *t = new statistics::Vector(
                    profilerStatsPtr, stat_name.c_str());
                t->init(m_num_controllers);
                t->flags(statistics::pdf | statistics::total |
                    statistics::oneline | statistics::nozero);
                transVec[state].push_back(t);
            }
        }
    }

    for (Memory_Event event = Memory_Event_FIRST;
                 event < Memory_Event_NUM; ++event) {
        std::string stat_name =
            "outTransLatHist." + Memory_Event_to_string(event);
        statistics::Histogram* t =
            new statistics::Histogram(&stats, stat_name.c_str());
        stats.outTransLatHist.push_back(t);
        t->init(5);
        t->flags(statistics::pdf | statistics::total |
                 statistics::oneline | statistics::nozero);

        statistics::Scalar* r = new statistics::Scalar(&stats,
                                             (stat_name + ".retries").c_str());
        stats.outTransLatHistRetries.push_back(r);
        r->flags(statistics::nozero);
    }

    for (Memory_Event event = Memory_Event_FIRST;
                 event < Memory_Event_NUM; ++event) {
        std::string stat_name = "inTransLatHist." +
                                Memory_Event_to_string(event);
        statistics::Scalar* r = new statistics::Scalar(&stats,
                                             (stat_name + ".total").c_str());
        stats.inTransLatTotal.push_back(r);
        r->flags(statistics::nozero);

        r = new statistics::Scalar(&stats,
                              (stat_name + ".retries").c_str());
        stats.inTransLatRetries.push_back(r);
        r->flags(statistics::nozero);

        stats.inTransLatHist.emplace_back();
        for (Memory_State initial_state = Memory_State_FIRST;
             initial_state < Memory_State_NUM; ++initial_state) {
            stats.inTransLatHist.back().emplace_back();
            for (Memory_State final_state = Memory_State_FIRST;
                 final_state < Memory_State_NUM; ++final_state) {
                std::string stat_name = "inTransLatHist." +
                    Memory_Event_to_string(event) + "." +
                    Memory_State_to_string(initial_state) + "." +
                    Memory_State_to_string(final_state);
                statistics::Histogram* t =
                    new statistics::Histogram(&stats, stat_name.c_str());
                stats.inTransLatHist.back().back().push_back(t);
                t->init(5);
                t->flags(statistics::pdf | statistics::total |
                         statistics::oneline | statistics::nozero);
            }
        }
    }
}

void
Memory_Controller::collateStats()
{
    for (Memory_Event event = Memory_Event_FIRST;
         event < Memory_Event_NUM; ++event) {
        for (unsigned int i = 0; i < m_num_controllers; ++i) {
            RubySystem *rs = params().ruby_system;
            std::map<uint32_t, AbstractController *>::iterator it =
                     rs->m_abstract_controls[MachineType_Memory].find(i);
            assert(it != rs->m_abstract_controls[MachineType_Memory].end());
            (*eventVec[event])[i] =
                ((Memory_Controller *)(*it).second)->getEventCount(event);
        }
    }

    for (Memory_State state = Memory_State_FIRST;
         state < Memory_State_NUM; ++state) {

        for (Memory_Event event = Memory_Event_FIRST;
             event < Memory_Event_NUM; ++event) {

            for (unsigned int i = 0; i < m_num_controllers; ++i) {
                RubySystem *rs = params().ruby_system;
                std::map<uint32_t, AbstractController *>::iterator it =
                         rs->m_abstract_controls[MachineType_Memory].find(i);
                assert(it != rs->m_abstract_controls[MachineType_Memory].end());
                (*transVec[state][event])[i] =
                    ((Memory_Controller *)(*it).second)->getTransitionCount(state, event);
            }
        }
    }
}

void
Memory_Controller::countTransition(Memory_State state, Memory_Event event)
{
    assert(m_possible[state][event]);
    m_counters[state][event]++;
    m_event_counters[event]++;
}
void
Memory_Controller::possibleTransition(Memory_State state,
                             Memory_Event event)
{
    m_possible[state][event] = true;
}

uint64_t
Memory_Controller::getEventCount(Memory_Event event)
{
    return m_event_counters[event];
}

bool
Memory_Controller::isPossible(Memory_State state, Memory_Event event)
{
    return m_possible[state][event];
}

uint64_t
Memory_Controller::getTransitionCount(Memory_State state,
                             Memory_Event event)
{
    return m_counters[state][event];
}

int
Memory_Controller::getNumControllers()
{
    return m_num_controllers;
}

MessageBuffer*
Memory_Controller::getMandatoryQueue() const
{
    return NULL;
}

MessageBuffer*
Memory_Controller::getMemReqQueue() const
{
    return m_requestToMemory_ptr;
}

MessageBuffer*
Memory_Controller::getMemRespQueue() const
{
    return m_responseFromMemory_ptr;
}

void
Memory_Controller::print(std::ostream& out) const
{
    out << "[Memory_Controller " << m_version << "]";
}

void Memory_Controller::resetStats()
{
    for (int state = 0; state < Memory_State_NUM; state++) {
        for (int event = 0; event < Memory_Event_NUM; event++) {
            m_counters[state][event] = 0;
        }
    }

    for (int event = 0; event < Memory_Event_NUM; event++) {
        m_event_counters[event] = 0;
    }

    AbstractController::resetStats();
}

// Set and Reset for tbe variable
void
Memory_Controller::set_tbe(Memory_TBE*& m_tbe_ptr, Memory_TBE* m_new_tbe)
{
  m_tbe_ptr = m_new_tbe;
}

void
Memory_Controller::unset_tbe(Memory_TBE*& m_tbe_ptr)
{
  m_tbe_ptr = NULL;
}

void
Memory_Controller::recordCacheTrace(int cntrl, CacheRecorder* tr)
{
}

// Actions
/** \brief  */
void
Memory_Controller::checkAllocateTBE(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing checkAllocateTBE\n");
        if ((((*m_storTBEs_ptr)).areNSlotsAvailable((1)))) {
        (((*m_storTBEs_ptr)).incrementReserved());
        {
            // Declare message
            GEM5_VAR_USED const CHIRequestMsg* in_msg_ptr;
            in_msg_ptr = dynamic_cast<const CHIRequestMsg *>(((*m_reqIn_ptr)).peek());
            if (in_msg_ptr == NULL) {
                // If the cast fails, this is the wrong inport (wrong message type).
                // Throw an exception, and the caller will decide to either try a
                // different inport or punt.
                throw RejectException();
            }
        {
            std::shared_ptr<CHIRequestMsg> out_msg = std::make_shared<CHIRequestMsg>(clockEdge());
            *out_msg = (*in_msg_ptr);
            ((*m_reqRdy_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles((0))));
        }
        }
    } else {
        {
            // Declare message
            GEM5_VAR_USED const CHIRequestMsg* in_msg_ptr;
            in_msg_ptr = dynamic_cast<const CHIRequestMsg *>(((*m_reqIn_ptr)).peek());
            if (in_msg_ptr == NULL) {
                // If the cast fails, this is the wrong inport (wrong message type).
                // Throw an exception, and the caller will decide to either try a
                // different inport or punt.
                throw RejectException();
            }
        #ifndef NDEBUG
        if (!(((*in_msg_ptr)).m_allowRetry)) {
            panic("Runtime Error at CHI-mem.sm:459: %s.\n", "assert failure");

        }
        #endif
        ;
        {
            std::shared_ptr<Memory_TriggerMsg> out_msg = std::make_shared<Memory_TriggerMsg>(clockEdge());
            (*out_msg).m_addr = ((*in_msg_ptr)).m_addr;
            (*out_msg).m_event = Memory_Event_Trigger_SendRetry;
            (*out_msg).m_retryDest = ((*in_msg_ptr)).m_requestor;
            (((*m_retryQueue_ptr)).emplace(((*in_msg_ptr)).m_addr, ((*in_msg_ptr)).m_requestor));
            ((*m_triggerQueue_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles((0))));
        }
        }
    }
    (((*m_reqIn_ptr)).dequeue((clockEdge())));

}

/** \brief  */
void
Memory_Controller::checkAllocateTBE_withCredit(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing checkAllocateTBE_withCredit\n");
    {
    // Declare message
    GEM5_VAR_USED const CHIRequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const CHIRequestMsg *>(((*m_reqIn_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
#ifndef NDEBUG
if (!((((*in_msg_ptr)).m_allowRetry == (false)))) {
    panic("Runtime Error at CHI-mem.sm:474: %s.\n", "assert failure");

}
#endif
;
{
    std::shared_ptr<CHIRequestMsg> out_msg = std::make_shared<CHIRequestMsg>(clockEdge());
    *out_msg = (*in_msg_ptr);
    ((*m_reqRdy_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles((0))));
}
}
(((*m_reqIn_ptr)).dequeue((clockEdge())));

}

/** \brief Allocate TBEs for a miss */
void
Memory_Controller::allocateTBE(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing allocateTBE\n");
    (((*m_storTBEs_ptr)).decrementReserved());
#ifndef NDEBUG
if (!((((*m_storTBEs_ptr)).areNSlotsAvailable((1))))) {
    panic("Runtime Error at CHI-mem.sm:485: %s.\n", "assert failure");

}
#endif
;
(((*m_TBEs_ptr)).allocate(addr));
set_tbe(m_tbe_ptr, (((*m_TBEs_ptr)).lookup(addr)));;
(*m_tbe_ptr).m_storSlot = (((*m_storTBEs_ptr)).addEntryToNewSlot());
(*m_tbe_ptr).m_addr = addr;
(*m_tbe_ptr).m_rxtxBytes = (0);
(*m_tbe_ptr).m_useDataSepResp = (false);

}

/** \brief Initialize TBE fields */
void
Memory_Controller::initializeFromReqTBE(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing initializeFromReqTBE\n");
    {
    // Declare message
    GEM5_VAR_USED const CHIRequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const CHIRequestMsg *>(((*m_reqRdy_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
(*m_tbe_ptr).m_requestor = ((*in_msg_ptr)).m_requestor;
    if (((*in_msg_ptr)).m_dataToFwdRequestor) {
        (*m_tbe_ptr).m_destination = ((*in_msg_ptr)).m_fwdRequestor;
    } else {
        (*m_tbe_ptr).m_destination = ((*in_msg_ptr)).m_requestor;
    }
    (*m_tbe_ptr).m_accAddr = ((*in_msg_ptr)).m_accAddr;
    (*m_tbe_ptr).m_accSize = ((*in_msg_ptr)).m_accSize;
    }

}

/** \brief Decrement pending writes */
void
Memory_Controller::decWritePending(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing decWritePending\n");
    #ifndef NDEBUG
if (!(((*m_pendingWrites_ptr) >= (1)))) {
    panic("Runtime Error at CHI-mem.sm:509: %s.\n", "assert failure");

}
#endif
;
(*m_pendingWrites_ptr) = ((*m_pendingWrites_ptr) - (1));

}

/** \brief Deallocate TBEs */
void
Memory_Controller::deallocateTBE(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing deallocateTBE\n");
    #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at CHI-mem.sm:514: %s.\n", "assert failure");

}
#endif
;
(((*m_storTBEs_ptr)).removeEntryFromSlot((*m_tbe_ptr).m_storSlot));
(((*m_TBEs_ptr)).deallocate(addr));
unset_tbe(m_tbe_ptr);;
    if (((((*m_retryQueue_ptr)).empty()) == (false))) {
        #ifndef NDEBUG
        if (!((((*m_storTBEs_ptr)).areNSlotsAvailable((1))))) {
            panic("Runtime Error at CHI-mem.sm:520: %s.\n", "assert failure");

        }
        #endif
        ;
        (((*m_storTBEs_ptr)).incrementReserved());
        Memory_RetryQueueEntry e
         = (((*m_retryQueue_ptr)).next());
        (((*m_retryQueue_ptr)).pop());
        {
            std::shared_ptr<Memory_TriggerMsg> out_msg = std::make_shared<Memory_TriggerMsg>(clockEdge());
            (*out_msg).m_addr = (e).m_addr;
            (*out_msg).m_retryDest = (e).m_retryDest;
            (*out_msg).m_event = Memory_Event_Trigger_SendPCrdGrant;
            ((*m_triggerQueue_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles((0))));
        }
    }

}

/** \brief Send receipt to requestor */
void
Memory_Controller::sendReadReceipt(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing sendReadReceipt\n");
    #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at CHI-mem.sm:533: %s.\n", "assert failure");

}
#endif
;
{
    std::shared_ptr<CHIResponseMsg> out_msg = std::make_shared<CHIResponseMsg>(clockEdge());
    (*out_msg).m_addr = addr;
    (*out_msg).m_type = CHIResponseType_ReadReceipt;
    (*out_msg).m_responder = m_machineID;
    (((*out_msg).m_Destination).add((*m_tbe_ptr).m_requestor));
    ((*m_rspOut_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_response_latency)));
}
(*m_tbe_ptr).m_useDataSepResp = (true);

}

/** \brief Send ack to requestor */
void
Memory_Controller::sendCompDBIDResp(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing sendCompDBIDResp\n");
    #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at CHI-mem.sm:545: %s.\n", "assert failure");

}
#endif
;
{
    std::shared_ptr<CHIResponseMsg> out_msg = std::make_shared<CHIResponseMsg>(clockEdge());
    (*out_msg).m_addr = addr;
    (*out_msg).m_type = CHIResponseType_CompDBIDResp;
    (*out_msg).m_responder = m_machineID;
    (((*out_msg).m_Destination).add((*m_tbe_ptr).m_requestor));
    ((*m_rspOut_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_response_latency)));
}

}

/** \brief Send request to memory */
void
Memory_Controller::sendMemoryRead(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing sendMemoryRead\n");
    #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at CHI-mem.sm:555: %s.\n", "assert failure");

}
#endif
;
{
    std::shared_ptr<MemoryMsg> out_msg = std::make_shared<MemoryMsg>(clockEdge());
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = MemoryRequestType_MEMORY_READ;
    (*out_msg).m_Sender = (*m_tbe_ptr).m_requestor;
    (*out_msg).m_MessageSize = MessageSizeType_Request_Control;
    (*out_msg).m_Len = (0);
    ((*m_requestToMemory_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_to_memory_controller_latency)));
}

}

/** \brief Send request to memory */
void
Memory_Controller::sendMemoryWrite(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing sendMemoryWrite\n");
    #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at CHI-mem.sm:566: %s.\n", "assert failure");

}
#endif
;
{
    std::shared_ptr<MemoryMsg> out_msg = std::make_shared<MemoryMsg>(clockEdge());
    (*out_msg).m_addr = (*m_tbe_ptr).m_accAddr;
    (*out_msg).m_Type = MemoryRequestType_MEMORY_WB;
    (*out_msg).m_Sender = (*m_tbe_ptr).m_requestor;
    (*out_msg).m_MessageSize = MessageSizeType_Writeback_Data;
    (*out_msg).m_DataBlk = (*m_tbe_ptr).m_dataBlk;
    (*out_msg).m_Len = (*m_tbe_ptr).m_accSize;
    ((*m_requestToMemory_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_to_memory_controller_latency)));
}
(((*m_tbe_ptr).m_dataBlkValid).clear());
(*m_pendingWrites_ptr) = ((*m_pendingWrites_ptr) + (1));

}

/** \brief Copies received memory data to TBE */
void
Memory_Controller::prepareSend(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing prepareSend\n");
    #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at CHI-mem.sm:580: %s.\n", "assert failure");

}
#endif
;
{
    // Declare message
    GEM5_VAR_USED const MemoryMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const MemoryMsg *>(((*m_responseFromMemory_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
(*m_tbe_ptr).m_dataBlk = ((*in_msg_ptr)).m_DataBlk;
}
(*m_tbe_ptr).m_rxtxBytes = (0);
(((*m_tbe_ptr).m_dataBlkValid).setMask((addressOffset((*m_tbe_ptr).m_accAddr, (*m_tbe_ptr).m_addr)), (*m_tbe_ptr).m_accSize));

}

/** \brief Copies received net data to TBE */
void
Memory_Controller::copyWriteDataToTBE(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing copyWriteDataToTBE\n");
    {
    // Declare message
    GEM5_VAR_USED const CHIDataMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const CHIDataMsg *>(((*m_datIn_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
#ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at CHI-mem.sm:590: %s.\n", "assert failure");

}
#endif
;
(((*m_tbe_ptr).m_dataBlk).copyPartial(((*in_msg_ptr)).m_dataBlk, ((*in_msg_ptr)).m_bitMask));
(((*m_tbe_ptr).m_dataBlkValid).orMask(((*in_msg_ptr)).m_bitMask));
(*m_tbe_ptr).m_rxtxBytes = ((*m_tbe_ptr).m_rxtxBytes + ((((*in_msg_ptr)).m_bitMask).count()));
}

}

/** \brief Send received data to requestor */
void
Memory_Controller::sendDataAndCheck(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing sendDataAndCheck\n");
    #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at CHI-mem.sm:598: %s.\n", "assert failure");

}
#endif
;
#ifndef NDEBUG
if (!(((*m_tbe_ptr).m_rxtxBytes < (*m_blockSize_ptr)))) {
    panic("Runtime Error at CHI-mem.sm:599: %s.\n", "assert failure");

}
#endif
;
{
    std::shared_ptr<CHIDataMsg> out_msg = std::make_shared<CHIDataMsg>(clockEdge());
    (*out_msg).m_addr = (*m_tbe_ptr).m_addr;
        if ((*m_tbe_ptr).m_useDataSepResp) {
            (*out_msg).m_type = CHIDataType_DataSepResp_UC;
        } else {
            (*out_msg).m_type = CHIDataType_CompData_UC;
        }
        (*out_msg).m_dataBlk = (*m_tbe_ptr).m_dataBlk;
        (((*out_msg).m_bitMask).setMask((*m_tbe_ptr).m_rxtxBytes, m_data_channel_size));
        (((*out_msg).m_Destination).add((*m_tbe_ptr).m_destination));
        ((*m_datOut_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_data_latency)));
    }
    (*m_tbe_ptr).m_rxtxBytes = ((*m_tbe_ptr).m_rxtxBytes + m_data_channel_size);
    Memory_Event next
     = Memory_Event_Trigger_SendDone;
    Cycles delay
     = (intToCycles((0)));
        if (((*m_tbe_ptr).m_rxtxBytes < (*m_blockSize_ptr))) {
            next = Memory_Event_Trigger_Send;
            delay = (intToCycles((1)));
        }
        {
            std::shared_ptr<Memory_TriggerMsg> out_msg = std::make_shared<Memory_TriggerMsg>(clockEdge());
            (*out_msg).m_addr = addr;
            (*out_msg).m_event = next;
            ((*m_triggerQueue_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(delay)));
        }

}

/** \brief Check if all data is received */
void
Memory_Controller::checkForReceiveCompletion(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing checkForReceiveCompletion\n");
    #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at CHI-mem.sm:631: %s.\n", "assert failure");

}
#endif
;
DPRINTF(RubySlicc, "CHI-mem.sm:632: rxtxBytes=%d\n", (*m_tbe_ptr).m_rxtxBytes);
#ifndef NDEBUG
if (!((((*m_tbe_ptr).m_rxtxBytes <= (*m_tbe_ptr).m_accSize) && ((*m_tbe_ptr).m_rxtxBytes > (0))))) {
    panic("Runtime Error at CHI-mem.sm:633: %s.\n", "assert failure");

}
#endif
;
    if (((*m_tbe_ptr).m_rxtxBytes == (*m_tbe_ptr).m_accSize)) {
        {
            std::shared_ptr<Memory_TriggerMsg> out_msg = std::make_shared<Memory_TriggerMsg>(clockEdge());
            (*out_msg).m_addr = addr;
            (*out_msg).m_event = Memory_Event_Trigger_ReceiveDone;
            ((*m_triggerQueue_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles((0))));
        }
        (*m_tbe_ptr).m_rxtxBytes = (0);
        #ifndef NDEBUG
        if (!((((*m_tbe_ptr).m_dataBlkValid).getMask((addressOffset((*m_tbe_ptr).m_accAddr, (*m_tbe_ptr).m_addr)), (*m_tbe_ptr).m_accSize)))) {
            panic("Runtime Error at CHI-mem.sm:640: %s.\n", "assert failure");

        }
        #endif
        ;
    }

}

/** \brief Pop request queue. */
void
Memory_Controller::popReqInQueue(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing popReqInQueue\n");
    (((*m_reqRdy_ptr)).dequeue((clockEdge())));

}

/** \brief Pop data queue. */
void
Memory_Controller::popDataInQueue(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing popDataInQueue\n");
    (((*m_datIn_ptr)).dequeue((clockEdge())));

}

/** \brief Pop trigger queue. */
void
Memory_Controller::popTriggerQueue(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing popTriggerQueue\n");
    (((*m_triggerQueue_ptr)).dequeue((clockEdge())));

}

/** \brief Pop memory queue. */
void
Memory_Controller::popMemoryQueue(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing popMemoryQueue\n");
    (((*m_responseFromMemory_ptr)).dequeue((clockEdge())));

}

/** \brief Stall and wait on the address */
void
Memory_Controller::stallRequestQueue(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing stallRequestQueue\n");
    {
    // Declare message
    GEM5_VAR_USED const CHIRequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const CHIRequestMsg *>(((*m_reqRdy_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
        stallBuffer(&((*m_reqRdy_ptr)), addr);
        (*m_reqRdy_ptr).stallMessage(addr, clockEdge());
        
}

}

/** \brief Wake up any requests waiting for this address */
void
Memory_Controller::wakeUpStalled(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing wakeUpStalled\n");
    (wakeUpAllBuffers(addr));

}

/** \brief  */
void
Memory_Controller::sendRetryAck(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing sendRetryAck\n");
    {
    // Declare message
    GEM5_VAR_USED const Memory_TriggerMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const Memory_TriggerMsg *>(((*m_triggerQueue_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<CHIResponseMsg> out_msg = std::make_shared<CHIResponseMsg>(clockEdge());
    (*out_msg).m_addr = ((*in_msg_ptr)).m_addr;
    (*out_msg).m_type = CHIResponseType_RetryAck;
    (*out_msg).m_responder = m_machineID;
    (((*out_msg).m_Destination).add(((*in_msg_ptr)).m_retryDest));
    ((*m_rspOut_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_response_latency)));
}
}

}

/** \brief  */
void
Memory_Controller::sendPCrdGrant(Memory_TBE*& m_tbe_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing sendPCrdGrant\n");
    {
    // Declare message
    GEM5_VAR_USED const Memory_TriggerMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const Memory_TriggerMsg *>(((*m_triggerQueue_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<CHIResponseMsg> out_msg = std::make_shared<CHIResponseMsg>(clockEdge());
    (*out_msg).m_addr = ((*in_msg_ptr)).m_addr;
    (*out_msg).m_type = CHIResponseType_PCrdGrant;
    (*out_msg).m_responder = m_machineID;
    (((*out_msg).m_Destination).add(((*in_msg_ptr)).m_retryDest));
    ((*m_rspOut_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_response_latency)));
}
}

}

Memory_Event
Memory_Controller::reqToEvent(const CHIRequestType& param_type)
{
    if ((param_type == CHIRequestType_WriteNoSnpPtl)) {
        return Memory_Event_WriteNoSnpPtl;
    } else {
            if ((param_type == CHIRequestType_WriteNoSnp)) {
                return Memory_Event_WriteNoSnp;
            } else {
                    if ((param_type == CHIRequestType_ReadNoSnp)) {
                        return Memory_Event_ReadNoSnp;
                    } else {
                            if ((param_type == CHIRequestType_ReadNoSnpSep)) {
                                return Memory_Event_ReadNoSnpSep;
                            } else {
                                panic("Runtime Error at CHI-mem.sm:137: %s.\n", ("Invalid CHIRequestType"));
                                ;
                            }
                        }
                    }
                }

}
Memory_Event
Memory_Controller::respToEvent(const CHIResponseType& param_type)
{
panic("Runtime Error at CHI-mem.sm:142: %s.\n", ("Invalid CHIResponseType"));
;

}
Memory_Event
Memory_Controller::dataToEvent(const CHIDataType& param_type)
{
    if ((param_type == CHIDataType_NCBWrData)) {
        return Memory_Event_WriteData;
    } else {
        panic("Runtime Error at CHI-mem.sm:149: %s.\n", ("Invalid CHIDataType"));
        ;
    }

}
Memory_State
Memory_Controller::getState(Memory_TBE* param_tbe, const Addr& param_addr)
{
    if ((param_tbe != NULL)) {
        #ifndef NDEBUG
        if (!(((*param_tbe).m_addr == param_addr))) {
            panic("Runtime Error at CHI-mem.sm:245: %s.\n", "assert failure");

        }
        #endif
        ;
        return (*param_tbe).m_state;
    } else {
        return Memory_State_READY;
    }

}
void
Memory_Controller::setState(Memory_TBE* param_tbe, const Addr& param_addr, const Memory_State& param_state)
{
    if ((param_tbe != NULL)) {
        #ifndef NDEBUG
        if (!(((*param_tbe).m_addr == param_addr))) {
            panic("Runtime Error at CHI-mem.sm:254: %s.\n", "assert failure");

        }
        #endif
        ;
        (*param_tbe).m_state = param_state;
    }

}
AccessPermission
Memory_Controller::getAccessPermission(const Addr& param_addr)
{
    if ((respondsTo(param_addr))) {
        Memory_TBE* tbe
         = (((*m_TBEs_ptr)).lookup(param_addr));
            if ((tbe != NULL)) {
                DPRINTF(RubySlicc, "CHI-mem.sm:263: %x %s,%s\n", param_addr, (*tbe).m_state, (Memory_State_to_permission((*tbe).m_state)));
                return (Memory_State_to_permission((*tbe).m_state));
            } else {
                DPRINTF(RubySlicc, "CHI-mem.sm:266: %x %s\n", param_addr, AccessPermission_Backing_Store);
                return AccessPermission_Backing_Store;
            }
        } else {
            DPRINTF(RubySlicc, "CHI-mem.sm:270: %x %s\n", param_addr, AccessPermission_NotPresent);
            return AccessPermission_NotPresent;
        }

}
void
Memory_Controller::setAccessPermission(const Addr& param_addr, const Memory_State& param_state)
{

}
void
Memory_Controller::functionalRead(const Addr& param_addr, Packet* param_pkt, WriteMask& param_mask)
{
    if ((respondsTo(param_addr))) {
        DPRINTF(RubySlicc, "CHI-mem.sm:280: functionalRead %x\n", param_addr);
        Memory_TBE* tbe
         = (((*m_TBEs_ptr)).lookup(param_addr));
            if (((param_mask).isEmpty())) {
                (functionalMemoryRead(param_pkt));
                ((param_mask).fillMask());
                DPRINTF(RubySlicc, "CHI-mem.sm:286: functionalRead mem %x %s\n", param_addr, param_mask);
            }
                if ((tbe != NULL)) {
                    WriteMask read_mask;
                    ((read_mask).setMask((addressOffset((*tbe).m_accAddr, (*tbe).m_addr)), (*tbe).m_accSize));
                    ((read_mask).andMask((*tbe).m_dataBlkValid));
                        if ((((read_mask).isEmpty()) == (false))) {
                            (testAndReadMask(param_addr, (*tbe).m_dataBlk, read_mask, param_pkt));
                            DPRINTF(RubySlicc, "CHI-mem.sm:297: functionalRead tbe %x %s %s %s\n", param_addr, (*tbe).m_dataBlk, read_mask, param_mask);
                            ((param_mask).orMask(read_mask));
                        }
                    }
                }

}
int
Memory_Controller::functionalWrite(const Addr& param_addr, Packet* param_pkt)
{
    if ((respondsTo(param_addr))) {
        int num_functional_writes
         = (0);
        Memory_TBE* tbe
         = (((*m_TBEs_ptr)).lookup(param_addr));
            if ((tbe != NULL)) {
                num_functional_writes = (num_functional_writes + (testAndWrite(param_addr, (*tbe).m_dataBlk, param_pkt)));
                DPRINTF(RubySlicc, "CHI-mem.sm:311: functionalWrite tbe %x %s\n", param_addr, (*tbe).m_dataBlk);
            }
            num_functional_writes = (num_functional_writes + (functionalMemoryWrite(param_pkt)));
            DPRINTF(RubySlicc, "CHI-mem.sm:314: functionalWrite mem %x\n", param_addr);
            return num_functional_writes;
        } else {
            return (0);
        }

}
void
Memory_Controller::printResources()
{
DPRINTF(RubySlicc, "CHI-mem.sm:327: Resources(avail/max): TBEs=%d/%d\n", (((*m_storTBEs_ptr)).size()), (((*m_storTBEs_ptr)).capacity()));
DPRINTF(RubySlicc, "CHI-mem.sm:329: Resources(in/out size): rdy=%d req=%d/%d rsp=%d/%d dat=%d/%d snp=%d/%d\n", (((*m_reqRdy_ptr)).getSize((curTick()))), (((*m_reqIn_ptr)).getSize((curTick()))), (((*m_reqOut_ptr)).getSize((curTick()))), (((*m_rspIn_ptr)).getSize((curTick()))), (((*m_rspOut_ptr)).getSize((curTick()))), (((*m_datIn_ptr)).getSize((curTick()))), (((*m_datOut_ptr)).getSize((curTick()))), (((*m_snpIn_ptr)).getSize((curTick()))), (((*m_snpOut_ptr)).getSize((curTick()))));

}
int
Memory_Controller::functionalWriteBuffers(PacketPtr& pkt)
{
    int num_functional_writes = 0;
num_functional_writes += m_reqOut_ptr->functionalWrite(pkt);
num_functional_writes += m_snpOut_ptr->functionalWrite(pkt);
num_functional_writes += m_rspOut_ptr->functionalWrite(pkt);
num_functional_writes += m_datOut_ptr->functionalWrite(pkt);
num_functional_writes += m_reqIn_ptr->functionalWrite(pkt);
num_functional_writes += m_snpIn_ptr->functionalWrite(pkt);
num_functional_writes += m_rspIn_ptr->functionalWrite(pkt);
num_functional_writes += m_datIn_ptr->functionalWrite(pkt);
num_functional_writes += m_reqRdy_ptr->functionalWrite(pkt);
num_functional_writes += m_requestToMemory_ptr->functionalWrite(pkt);
num_functional_writes += m_responseFromMemory_ptr->functionalWrite(pkt);
num_functional_writes += m_triggerQueue_ptr->functionalWrite(pkt);
    return num_functional_writes;
}
bool
Memory_Controller::functionalReadBuffers(PacketPtr& pkt)
{
if (m_reqOut_ptr->functionalRead(pkt)) return true;
if (m_snpOut_ptr->functionalRead(pkt)) return true;
if (m_rspOut_ptr->functionalRead(pkt)) return true;
if (m_datOut_ptr->functionalRead(pkt)) return true;
if (m_reqIn_ptr->functionalRead(pkt)) return true;
if (m_snpIn_ptr->functionalRead(pkt)) return true;
if (m_rspIn_ptr->functionalRead(pkt)) return true;
if (m_datIn_ptr->functionalRead(pkt)) return true;
if (m_reqRdy_ptr->functionalRead(pkt)) return true;
if (m_requestToMemory_ptr->functionalRead(pkt)) return true;
if (m_responseFromMemory_ptr->functionalRead(pkt)) return true;
if (m_triggerQueue_ptr->functionalRead(pkt)) return true;
    return false;
}

bool
Memory_Controller::functionalReadBuffers(PacketPtr& pkt, WriteMask &mask)
{
    bool read = false;
if (m_reqOut_ptr->functionalRead(pkt, mask)) read = true;
if (m_snpOut_ptr->functionalRead(pkt, mask)) read = true;
if (m_rspOut_ptr->functionalRead(pkt, mask)) read = true;
if (m_datOut_ptr->functionalRead(pkt, mask)) read = true;
if (m_reqIn_ptr->functionalRead(pkt, mask)) read = true;
if (m_snpIn_ptr->functionalRead(pkt, mask)) read = true;
if (m_rspIn_ptr->functionalRead(pkt, mask)) read = true;
if (m_datIn_ptr->functionalRead(pkt, mask)) read = true;
if (m_reqRdy_ptr->functionalRead(pkt, mask)) read = true;
if (m_requestToMemory_ptr->functionalRead(pkt, mask)) read = true;
if (m_responseFromMemory_ptr->functionalRead(pkt, mask)) read = true;
if (m_triggerQueue_ptr->functionalRead(pkt, mask)) read = true;
    return read;
}

} // namespace ruby
} // namespace gem5
